# Seq2Seq Model Architecture
# - Add beam search logic to model.
#   - Beam Search:
#       - Beam search keeps track of multiple hypotheses (candidate sequences) at each time step and selects the top
#         `beam width` sequences based on the cumulative log probabilities.
#
# Training run metrics:
#   - Epochs: 5
#
#   - Train Loss (Smoothed): 0.365
#   - Train Accuracy (Smoothed): 0.618
#   - Train Perplexity (Smoothed): 1.45
#
#   - Validation Loss (Smoothed): 0.289
#   - Validation Accuracy (Smoothed): 0.636
#   - Validation Perplexity (Smoothed): 1.34
#   - Validation BLEU Score (Smoothed): 0.0177
#
#   - Test Loss (Smoothed): 0.230
#   - Test Accuracy (Smoothed): 0.651
#   - Test Perplexity (Smoothed): 1.26
#   - Test BLEU Score (Smoothed): 0.0182
#
#     - Slight reduction in BLEU score compared to model V15, all other metrics identical.
#
# Training Performance Evaluation
# 1. Training vs Validation Accuracy, Loss, Perplexity and BLEU Score:
#     - Train Accuracy: 0.618
#     - Validation Accuracy: 0.636
#     - Difference: +0.0180 (+2.91%)
#
#       - Identical data to model v15.
#
#     - Train Loss: 0.365
#     - Validation Loss: 0.289
#     - Difference: -0.0760 (-20.8%)
#
#       - Identical data to model v15.
#
#     - Train Perplexity: 1.45
#     - Validation Perplexity: 1.34
#     - Difference: -0.110 (-7.59%)
#
#       - Identical data to model v15.
#
# 2. Validation vs Testing Accuracy, Loss, Perplexity and BLEU Score:
#   - Validation Accuracy:  0.636
#   - Testing Accuracy: 0.651
#   - Difference: +0.015 (+2.36%)
#
#     - Identical data to model v15.
#
#   - Validation Loss: 0.289
#   - Testing Loss: 0.230
#   - Difference: -0.0590 (-20.42%)
#
#     - Identical data to model v15.
#
#   - Validation Perplexity: 1.34
#   - Testing Perplexity: 1.26
#   - Difference: -0.0800 (-5.97%)
#
#     - Identical data to model v15.
#
#   - Validation BLEU Score: 0.0177
#   - Testing BLEU Score: 0.0182
#   - Difference: +0.0005 (+2.82%)
#
#     - Despite there being an improvement of +7.14% from validation to testing BLEU score, absolute BLEU score is
#       very low (~1.8%).
#     - Slight reduction in BLEU score compared to model V15
#

# Data Configuration and Hyperparameters
data:
  products_file: 'data/preprocessed/liu-et-al/products_smiles'
  reactants_file: 'data/preprocessed/liu-et-al/reactants_smiles'
  products_valid_file: 'data/preprocessed/liu-et-al/validation_products_smiles'
  reactants_valid_file: 'data/preprocessed/liu-et-al/validation_reactants_smiles'
  tokenizer_save_path: 'data/training/liu-et-al/model-v16/tokenizer/model_v16_tokenizer.json'
  max_encoder_seq_length: 140
  max_decoder_seq_length: 140
  batch_size: 32
  test_size: 0.3
  random_state: 4

# Model Configuration and Hyperparameters
model:
  input_vocab_size: null  # To be set dynamically based on tokenizer
  output_vocab_size: null  # To be set dynamically based on tokenizer
  attention_dim: 256
  encoder_embedding_dim: 128
  decoder_embedding_dim: 256
  units: 256
  encoder_num_layers: 2
  decoder_num_layers: 4
  beam_width: 5
  weight_decay: null
  dropout_rate: 0.2
  learning_rate: 0.0001
  metrics: ['accuracy']

# Training Configuration and Hyperparameters
training:
  epochs: 5
  patience: 5
  model_save_path: 'data/training/liu-et-al/model-v16/model/saved_model'
  model_save_dir: 'data/training/liu-et-al/model-v16/model'
  test_metrics_dir: 'data/training/liu-et-al/model-v16/evaluate'
  log_dir: 'logs/liu-et-al/model-v16'
  checkpoint_dir: 'data/training/liu-et-al/model-v16/checkpoints'
  num_samples: null # Number of samples to use for debugging model

# Environment Configuration
env:
  determinism:
    python_seed: "44478977"
    random_seed: 440651
    numpy_seed: 110789
    tf_seed: 61592