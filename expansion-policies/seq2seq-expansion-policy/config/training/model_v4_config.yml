# Seq2Seq Model Architecture
# - The following architectural changes were made to model V3:
#   * Add Tahn Activation Function:
#     - Add `activation='tanh' to encoder `Dense` layers (self.enc_state_h and self.enc_state_c).
#     - This means that the `Dense` layers apply a linear transformation followed by the tahn activation function.
#     - As a result, the output of each layer is passed through the tanh function, which maps values to a range between
#       -1 and 1.
#     - The effect on the Decoder's initial sates is as follows:
#         * The outputs of the Dense layers are used to initialize the decoder's LSTM hidden state (h) and cell state (c).
#         * Since LSTM hidden states typically use the tanh activation internally, initializing them with values in the
#           range [−1,1][−1,1] is appropriate.
#     - Potential benefits include:
#         * Stability: Helps in stabilizing the training process by providing initial states within the expected range.
#         * Compatibility: Aligns the initial state values with the internal activations of the LSTM, which can improve
#           performance.
#     - To conserve time, this change will be measured over 5 epochs. To evaluate the effect of this change on model
#       performance, we will compare this to the first 5 epochs of model V3
# - Based on training metrics below, model has performed worse with tanh activation function.
#
# - Training run metrics:
#   - Epochs: 5
#   - Train Loss (Smoothed): 0.696
#   - Train Accuracy (Smoothed): 0.499
#
#   - Validation Loss (Smoothed): 0.583
#   - Validation Accuracy (Smoothed): 0.526
#
#   - Test Loss (Smoothed): N/A (Not recorded as comparison cannot be made to V3 for test metrics)
#   - Test Accuracy (Smoothed): N/A (Not recorded as comparison cannot be made to V3 for test metrics)

# Data Configuration and Hyperparameters
data:
  products_file: 'data/preprocessed/liu-et-al/products_smiles'
  reactants_file: 'data/preprocessed/liu-et-al/reactants_smiles'
  products_valid_file: 'data/preprocessed/liu-et-al/validation_products_smiles'
  reactants_valid_file: 'data/preprocessed/liu-et-al/validation_reactants_smiles'
  tokenizer_save_path: 'data/training/liu-et-al/model-v4/tokenizer/model_v4_tokenizer.json'
  max_encoder_seq_length: 140
  max_decoder_seq_length: 140
  batch_size: 32
  test_size: 0.3
  random_state: 4

# Model Configuration and Hyperparameters
model:
  input_vocab_size: null  # To be set dynamically based on tokenizer
  output_vocab_size: null  # To be set dynamically based on tokenizer
  embedding_dim: 256
  units: 256
  dropout_rate: 0.2
  learning_rate: 0.0001
  metrics: ['accuracy']

# Training Configuration and Hyperparameters
training:
  epochs: 5
  patience: 5
  model_save_path: 'data/training/liu-et-al/model-v4/model'
  log_dir: 'logs/liu-et-al/model-v4'
  checkpoint_dir: 'data/training/liu-et-al/model-v4/checkpoints'
  num_samples: null # Number of samples to use for debugging model

# Environment Configuration
env:
  determinism:
    python_seed: "44478977"
    random_seed: 440651
    numpy_seed: 110789
    tf_seed: 61592