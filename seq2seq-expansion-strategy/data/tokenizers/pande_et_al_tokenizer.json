{"class_name": "Tokenizer", "config": {"num_words": null, "filters": "", "lower": false, "split": " ", "char_level": false, "oov_token": "<OOV>", "document_count": 140, "word_counts": "{\"<START>\": 140, \"\": 6193, \"<END>\": 140, \"[ C @ H ]\": 19, \"[ C @ @ H ]\": 26, \"[ N + ]\": 12, \"[ O - ]\": 10, \"[ n H ]\": 11, \"[ N - ]\": 3, \"[ S i ]\": 3, \"[ L i ]\": 1, \"[ M g + ]\": 1}", "word_docs": "{\"\": 140, \"<START>\": 140, \"<END>\": 140, \"[ C @ H ]\": 13, \"[ C @ @ H ]\": 21, \"[ N + ]\": 11, \"[ O - ]\": 9, \"[ n H ]\": 10, \"[ N - ]\": 2, \"[ S i ]\": 3, \"[ L i ]\": 1, \"[ M g + ]\": 1}", "index_docs": "{\"2\": 140, \"3\": 140, \"4\": 140, \"6\": 13, \"5\": 21, \"7\": 11, \"9\": 9, \"8\": 10, \"10\": 2, \"11\": 3, \"12\": 1, \"13\": 1}", "index_word": "{\"1\": \"<OOV>\", \"2\": \"\", \"3\": \"<START>\", \"4\": \"<END>\", \"5\": \"[ C @ @ H ]\", \"6\": \"[ C @ H ]\", \"7\": \"[ N + ]\", \"8\": \"[ n H ]\", \"9\": \"[ O - ]\", \"10\": \"[ N - ]\", \"11\": \"[ S i ]\", \"12\": \"[ L i ]\", \"13\": \"[ M g + ]\"}", "word_index": "{\"<OOV>\": 1, \"\": 2, \"<START>\": 3, \"<END>\": 4, \"[ C @ @ H ]\": 5, \"[ C @ H ]\": 6, \"[ N + ]\": 7, \"[ n H ]\": 8, \"[ O - ]\": 9, \"[ N - ]\": 10, \"[ S i ]\": 11, \"[ L i ]\": 12, \"[ M g + ]\": 13}"}}